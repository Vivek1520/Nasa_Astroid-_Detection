# -*- coding: utf-8 -*-
"""A04_NASAExp 4b._Succesful_ipynb_ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wBD-0bCPRF4CN5WrccZoO8Zo0Czs7jYP
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os

# Change the working directory to the directory containing the file
# Extract directory path from the file path
file_path = '/content/drive/MyDrive/ML/nasa.csv'
directory_path = os.path.dirname(file_path)
os.chdir(directory_path) # Change to the directory

# Load the dataset
df = pd.read_csv(file_path)  # Now read the file using its path

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics import accuracy_score
import numpy as np

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/ML/nasa.csv')

# Label encoding for categorical features
label_encoder = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'bool':
        df[column] = df[column].astype(int)  # Convert boolean to int
    elif df[column].dtype == 'object':
        df[column] = label_encoder.fit_transform(df[column])  # Label encoding

# Handle missing values
df.fillna(df.median(), inplace=True)

# Remove zero variance features
non_zero_variance_features = df.loc[:, df.var() > 0]
X = non_zero_variance_features.drop(columns=['Hazardous'])
y = df['Hazardous']

# Scale numeric features
numeric_columns = X.select_dtypes(include=[np.number]).columns
scaler = MinMaxScaler()
X[numeric_columns] = scaler.fit_transform(X[numeric_columns])

# Initialize variables for tracking the best random state and accuracy
best_random_state = 0
best_accuracy = 0

# Iterate over random states to find the best one based on accuracy
for i in range(1000):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_random_state = i

print("Best random state for random forest:", best_random_state)
print("Best accuracy:", best_accuracy)
print("******************************************************************************************************************************")

# Use stratified split to maintain class distribution with the best random state
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=best_random_state)

# Initialize Random Forest model
model = RandomForestClassifier()

# Fit the Random Forest model
model.fit(X_train, y_train)

# Calculate training accuracy
training_accuracy = model.score(X_train, y_train)

# Make predictions on the testing data
y_pred = model.predict(X_test)

# Calculate test accuracy
test_accuracy = accuracy_score(y_test, y_pred)

# Cross-Validation with the best random state for splitting
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=best_random_state)
cv_scores = cross_val_score(model, X, y, cv=skf)
average_cv_accuracy = np.mean(cv_scores)

# Print results
print("Training Accuracy of random forest:", training_accuracy)
print("Testing Accuracy ", test_accuracy)
print("Average Cross-Validation Accuracy:", average_cv_accuracy)

# Logistic Regression
lr_model = LogisticRegression(random_state=10)
lr_model.fit(X_train, y_train)
lr_train_score = lr_model.score(X_train, y_train)
lr_test_score = lr_model.score(X_test, y_test)
lr_cv_score = cross_val_score(lr_model, X, y, cv=10).mean()
print("\nLogistic Regression:")
print("Training Accuracy:", lr_train_score)
print("Testing Accuracy:", lr_test_score)
print("Cross-Validation Accuracy:", lr_cv_score)

# Support Vector Machine
svm_model = SVC(random_state=10)
svm_model.fit(X_train, y_train)
svm_train_score = svm_model.score(X_train, y_train)
svm_test_score = svm_model.score(X_test, y_test)
svm_cv_score = cross_val_score(svm_model, X, y, cv=10).mean()
print("\nSupport Vector Machine:")
print("Training Accuracy:", svm_train_score)
print("Testing Accuracy:", svm_test_score)
print("Cross-Validation Accuracy:", svm_cv_score)

# XGBoost
xgb_model = xgb.XGBClassifier(random_state=9)
xgb_model.fit(X_train, y_train)
xgb_train_score = xgb_model.score(X_train, y_train)
xgb_test_score = xgb_model.score(X_test, y_test)
xgb_cv_score = cross_val_score(xgb_model, X, y, cv=10).mean()

print("\nXGBoost:")
print("Training Accuracy:", xgb_train_score)
print("Testing Accuracy:", xgb_test_score)
print("Cross-Validation Accuracy:", xgb_cv_score)

# K-Nearest Neighbors (KNN) - Dynamically find the best k using cross-validation and test accuracy
best_knn_accuracy = 0
best_k = 1

# Iterate over a range of k values (1 to 50)
for k in range(1, 51):
    knn_model = KNeighborsClassifier(n_neighbors=k)
    knn_model.fit(X_train, y_train)

    # Evaluate on the test set
    knn_test_score = knn_model.score(X_test, y_test)

    # Update the best k if current accuracy is better
    if knn_test_score > best_knn_accuracy:
        best_knn_accuracy = knn_test_score
        best_k = k

# Print the best value of k and corresponding accuracy
print(f"\nBest value of k: {best_k}")
print(f"Best KNN Testing Accuracy: {best_knn_accuracy}")

# Final evaluation of KNN using the best k
knn_model = KNeighborsClassifier(n_neighbors=best_k)
knn_model.fit(X_train, y_train)
knn_train_score = knn_model.score(X_train, y_train)
knn_test_score = knn_model.score(X_test, y_test)
knn_cv_score = cross_val_score(knn_model, X, y, cv=10).mean()

# Print final results
print("\nK-Nearest Neighbors with Best k:")
print("Training Accuracy:", knn_train_score)
print("Testing Accuracy:", knn_test_score)
print("Cross-Validation Accuracy:", knn_cv_score)


# Evaluate KNN with the best n_neighbors
knn_model = KNeighborsClassifier(n_neighbors=best_n_neighbors)
knn_model.fit(X_train, y_train)
knn_train_score = knn_model.score(X_train, y_train)
knn_test_score = knn_model.score(X_test, y_test)
knn_cv_score = cross_val_score(knn_model, X, y, cv=10).mean()

print("\nK-Nearest Neighbors with Best n_neighbors:")
print("Training Accuracy:", knn_train_score)
print("Testing Accuracy:", knn_test_score)
print("Cross-Validation Accuracy:", knn_cv_score)

import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import xgboost as xgb



# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Create individual models
rf_model = RandomForestClassifier(random_state=best_random_state)
knn_model = KNeighborsClassifier(n_neighbors=5)
lr_model = LogisticRegression()  # Increased max_iter for convergence
svm_model = SVC(random_state=10, probability=True)
xgb_model = xgb.XGBClassifier(random_state=10)

# Hyperparameter tuning for hard voting
hard_voting_params = {
    'weights': [[1, 1, 1, 1, 1],
                [2, 1, 1, 1, 1],
                [1, 2, 1, 1, 1],
                [1, 1, 2, 1, 1],
                [1, 1, 1, 2, 1]]
}

hard_voting_model = GridSearchCV(
    VotingClassifier(estimators=[
        ('rf', rf_model),
        ('knn', knn_model),
        ('lr', lr_model),
        ('svm', svm_model),
        ('xgb', xgb_model)
    ], voting='hard'),
    param_grid=hard_voting_params,
    cv=5
)

hard_voting_model.fit(X_train, y_train)

# Hyperparameter tuning for soft voting
soft_voting_params = {
    'weights': [[1, 1, 1, 1, 1],
                [2, 1, 1, 1, 1],
                [1, 2, 1, 1, 1],
                [1, 1, 2, 1, 1],
                [1, 1, 1, 2, 1]]
}

soft_voting_model = GridSearchCV(
    VotingClassifier(estimators=[
        ('rf', rf_model),
        ('knn', knn_model),
        ('lr', lr_model),
        ('svm', svm_model),
        ('xgb', xgb_model)
    ], voting='soft'),
    param_grid=soft_voting_params,
    cv=5
)

soft_voting_model.fit(X_train, y_train)

# XGBoost model fitting and evaluation
xgb_model.fit(X_train, y_train)
xgb_cv_score = cross_val_score(xgb_model, X, y, cv=10).mean()

# Evaluate the models
hard_voting_cv_score = cross_val_score(hard_voting_model.best_estimator_, X, y, cv=10).mean()
soft_voting_cv_score = cross_val_score(soft_voting_model.best_estimator_, X, y, cv=10).mean()

# Display cross-validation scores
print("Hard Voting Cross-Validation Accuracy:", hard_voting_cv_score)
print("Soft Voting Cross-Validation Accuracy:", soft_voting_cv_score)
print("XGBoost Cross-Validation Accuracy:", xgb_cv_score)

# Assign the best performing model to clf
if xgb_cv_score > max(hard_voting_cv_score, soft_voting_cv_score):
    clf = xgb_model
    best_model = "XGBoost"
elif soft_voting_cv_score > hard_voting_cv_score:
    clf = soft_voting_model.best_estimator_
    best_model = "Soft Voting"
else:
    clf = hard_voting_model.best_estimator_
    best_model = "Hard Voting"

print("\nBest performing model:", best_model)

# K Fold Cross Validation Accuracy
cv_scores = cross_val_score(clf, X_train, y_train, cv=10)
print("Cross-Validation Scores: ", cv_scores)

# Average Accuracy of Cross Validation
average_accuracy = np.mean(cv_scores)
print("Average Accuracy of Cross Validation: ", average_accuracy)

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import xgboost as xgb
import numpy as np


# Apply feature selection using chi-square
X_non_negative = np.maximum(X, 0)
select_k_best = SelectKBest(score_func=chi2, k=10)
X_top5 = select_k_best.fit_transform(X_non_negative, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_top5, y, test_size=0.2)

# Create individual models with default parameters
rf_model = RandomForestClassifier(random_state=best_random_state)
knn_model = KNeighborsClassifier()
lr_model = LogisticRegression()
svm_model = SVC(random_state=10, probability=True)
xgb_model = xgb.XGBClassifier(random_state=10)

# Hard Voting
hard_voting_model = VotingClassifier(estimators=[('rf', rf_model), ('knn', knn_model), ('lr', lr_model), ('svm', svm_model),('xgb', xgb_model)], voting='hard')
hard_voting_cv_scores = cross_val_score(hard_voting_model, X_top5, y, cv=10)
hard_voting_model.fit(X_train, y_train)
hard_voting_test_score = hard_voting_model.score(X_test, y_test)
avg_hard_voting_cv_score = np.mean(hard_voting_cv_scores)

# Soft Voting
soft_voting_model = VotingClassifier(estimators=[('rf', rf_model), ('knn', knn_model), ('lr', lr_model), ('svm', svm_model),('xgb', xgb_model)], voting='soft')
soft_voting_cv_scores = cross_val_score(soft_voting_model, X_top5, y, cv=10)
soft_voting_model.fit(X_train, y_train)
soft_voting_test_score = soft_voting_model.score(X_test, y_test)
avg_soft_voting_cv_score = np.mean(soft_voting_cv_scores)

# XGBoost

xgb_cv_scores = cross_val_score(xgb_model, X_top5, y, cv=10)
xgb_model.fit(X_train, y_train)
xgb_test_score = xgb_model.score(X_test, y_test)
avg_xgb_cv_score = np.mean(xgb_cv_scores)

# Print the results
print("Hard Voting Test Accuracy:", hard_voting_test_score)
print("Average Hard Voting Cross-Validation Score:", avg_hard_voting_cv_score)

print("Soft Voting Test Accuracy:", soft_voting_test_score)
print("Average Soft Voting Cross-Validation Score:", avg_soft_voting_cv_score)


# Assign the best performing model to clf
if avg_xgb_cv_score > max(avg_hard_voting_cv_score, avg_soft_voting_cv_score):
    clf = xgb_model
    best_model = "XGBoost"
elif avg_soft_voting_cv_score > avg_hard_voting_cv_score:
    clf = soft_voting_model
    best_model = "Soft Voting"
else:
    clf = hard_voting_model
    best_model = "Hard Voting"

print("\nBest performing model:", best_model)

import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import xgboost as xgb

# Apply feature selection using chi-square (ensure X has non-negative values)
X_non_negative = np.maximum(X, 0)
select_k_best = SelectKBest(score_func=chi2, k=10)
X_top5 = select_k_best.fit_transform(X_non_negative, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_top5, y, test_size=0.2, random_state=best_random_state)

# Create individual models with default parameters
rf_model = RandomForestClassifier(random_state=best_random_state)
knn_model = KNeighborsClassifier()
lr_model = LogisticRegression(max_iter=1000)  # Ensure convergence
svm_model = SVC(random_state=10, probability=True)
xgb_model = xgb.XGBClassifier(random_state=10)

# Hard Voting
hard_voting_model = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('knn', knn_model),
    ('lr', lr_model),
    ('svm', svm_model),
    ('xgb', xgb_model)
], voting='hard')

# Perform cross-validation and fit hard voting model
hard_voting_cv_scores = cross_val_score(hard_voting_model, X_top5, y, cv=10)
hard_voting_model.fit(X_train, y_train)
hard_voting_test_score = hard_voting_model.score(X_test, y_test)
avg_hard_voting_cv_score = np.mean(hard_voting_cv_scores)

# Soft Voting
soft_voting_model = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('knn', knn_model),
    ('lr', lr_model),
    ('svm', svm_model),
    ('xgb', xgb_model)
], voting='soft')

# Perform cross-validation and fit soft voting model
soft_voting_cv_scores = cross_val_score(soft_voting_model, X_top5, y, cv=10)
soft_voting_model.fit(X_train, y_train)
soft_voting_test_score = soft_voting_model.score(X_test, y_test)
avg_soft_voting_cv_score = np.mean(soft_voting_cv_scores)

# XGBoost model
xgb_cv_scores = cross_val_score(xgb_model, X_top5, y, cv=10)
xgb_model.fit(X_train, y_train)
xgb_test_score = xgb_model.score(X_test, y_test)
avg_xgb_cv_score = np.mean(xgb_cv_scores)

# Print the results for each model
print("Hard Voting Test Accuracy:", hard_voting_test_score)
print("Average Hard Voting Cross-Validation Score:", avg_hard_voting_cv_score)

print("Soft Voting Test Accuracy:", soft_voting_test_score)
print("Average Soft Voting Cross-Validation Score:", avg_soft_voting_cv_score)

print("XGBoost Test Accuracy:", xgb_test_score)
print("Average XGBoost Cross-Validation Score:", avg_xgb_cv_score)

# Assign the best performing model to clf
if avg_xgb_cv_score > max(avg_hard_voting_cv_score, avg_soft_voting_cv_score):
    clf = xgb_model
    best_model = "XGBoost"
elif avg_soft_voting_cv_score > avg_hard_voting_cv_score:
    clf = soft_voting_model
    best_model = "Soft Voting"
else:
    clf = hard_voting_model
    best_model = "Hard Voting"

print("\nBest performing model:", best_model)

# Final Cross-Validation Accuracy of the best model
final_cv_scores = cross_val_score(clf, X_train, y_train, cv=10)
print("Final Cross-Validation Scores:", final_cv_scores)
average_final_cv_accuracy = np.mean(final_cv_scores)
print("Average Final Cross-Validation Accuracy:", average_final_cv_accuracy)